{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKSvjxkX67pF"
      },
      "source": [
        "# Transformación de audio a espectrograma\n",
        "\n",
        "Este notebook tiene como objetivo transformar los archivos de audio del dataset GTZAN Genre Collection en espectrogramas Mel de 3 segundos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Id4Xw5bF66D9"
      },
      "source": [
        "## Librerias necesarias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "D2YSeae661e0"
      },
      "outputs": [],
      "source": [
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "from glob import glob\n",
        "from PIL import Image\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbnE4cP2-rvF"
      },
      "source": [
        "## Parametros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "TEkF6MTN-rUa"
      },
      "outputs": [],
      "source": [
        "# Constantes\n",
        "SAMPLE_RATE = 22050\n",
        "SEGMENT_DURATION = 3\n",
        "NUMBER_OF_SEGMENTS = 10\n",
        "TIME_STRETCH_RATES = [0.85, 1.15] "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBYwxerVAg0e"
      },
      "source": [
        "### Configuración de carpetas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4tGhvhSdAgXq",
        "outputId": "a061d84c-3521-47bc-f3e9-90d5eadad2ef"
      },
      "outputs": [],
      "source": [
        "AUDIO_INPUT_FOLDER = \"Data/genresWav\"\n",
        "SPECTROGRAM_OUTPUT_FOLDER = \"Data/AugmentedSpectrograms\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Funcion para crear espectrogramas, parametros:\n",
        "\n",
        "- Sample rate: 22050\n",
        "- n_mels: 128\n",
        "- Duration: 3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ehCt_4bOEtbZ"
      },
      "outputs": [],
      "source": [
        "def generate_mel_spectrogram(audio_segment, sr):\n",
        "    mel = librosa.feature.melspectrogram(y=audio_segment, sr=sr, n_mels=128)\n",
        "    return librosa.power_to_db(mel, ref=np.max)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lkM14u0PLr9-",
        "outputId": "368ad175-ef2c-4264-bf6a-23e45f719bab"
      },
      "outputs": [],
      "source": [
        "# def process_audio_files():\n",
        "#     try:\n",
        "#         # Se obtiene la lista de archivos de audio\n",
        "#         segment_length = int(SEGMENT_DURATION * SAMPLE_RATE)\n",
        "#         total_images = 0\n",
        "\n",
        "#         genres = [d for d in os.listdir(AUDIO_INPUT_FOLDER)\n",
        "#                   if os.path.isdir(os.path.join(AUDIO_INPUT_FOLDER, d))]\n",
        "\n",
        "#         for genre in genres:\n",
        "\n",
        "#             # Se obtiene la lista de archivos de audio por género\n",
        "#             genre_path = os.path.join(AUDIO_INPUT_FOLDER, genre)\n",
        "#             audio_files = glob(os.path.join(genre_path, '*.wav'))\n",
        "\n",
        "#             if not audio_files:\n",
        "#                 continue\n",
        "\n",
        "#             print(f\"\\nGenre '{genre}': {len(audio_files)} files found\")\n",
        "\n",
        "#             # Se mezclan los archivos de audio y se dividen en conjuntos de entrenamiento, validación y prueba\n",
        "#             random.shuffle(audio_files)\n",
        "#             train_split = int(0.6 * len(audio_files))\n",
        "#             val_split = int(0.8 * len(audio_files))\n",
        "\n",
        "#             sets = {\n",
        "#                 'train': audio_files[:train_split],\n",
        "#                 'val': audio_files[train_split:val_split],\n",
        "#                 'test': audio_files[val_split:]\n",
        "#             }\n",
        "\n",
        "#             for split, files in sets.items():\n",
        "#                 print(f\"  {split}: {len(files)} files\")\n",
        "\n",
        "#                 for path in files:\n",
        "#                     try:\n",
        "#                         # Se carga el archivo de audio y se obtiene la carpeta de salida\n",
        "#                         audio, sr = librosa.load(path, sr=SAMPLE_RATE)\n",
        "#                         file_stem = os.path.splitext(os.path.basename(path))[0]\n",
        "#                         output_dir = os.path.join(SPECTROGRAM_OUTPUT_FOLDER, split, genre)\n",
        "#                         os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "#                         # Se crea un espectrograma para cada segmento de audio\n",
        "#                         for i in range(NUMBER_OF_SEGMENTS):\n",
        "#                             start = i * segment_length\n",
        "#                             end = start + segment_length\n",
        "#                             segment = audio[start:end]\n",
        "\n",
        "#                             if len(segment) != segment_length:\n",
        "#                                 continue\n",
        "\n",
        "#                             spec = generate_mel_spectrogram(segment, sr)\n",
        "\n",
        "\n",
        "#                             # Se guarda el espectrograma como imagen\n",
        "#                             img_path = os.path.join(output_dir, f\"{file_stem}_seg_{i+1}.png\")\n",
        "#                             plt.imsave(img_path, np.flipud(spec), cmap='viridis', origin='lower')\n",
        "#                             total_images += 1\n",
        "\n",
        "#                     except Exception as e:\n",
        "#                         print(f\"Error in {path}: {e}\")\n",
        "\n",
        "#         print(f\"\\nDone! Total spectrograms saved: {total_images}\")\n",
        "\n",
        "#     except Exception as e:\n",
        "#         print(f\"Error: {e}\")\n",
        "\n",
        "# process_audio_files()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Genre 'pop': 100 files found\n",
            "  Processing split 'train': 60 files\n",
            "  Processing split 'val': 20 files\n",
            "  Processing split 'test': 20 files\n",
            "\n",
            "Genre 'rock': 100 files found\n",
            "  Processing split 'train': 60 files\n",
            "  Processing split 'val': 20 files\n",
            "  Processing split 'test': 20 files\n",
            "\n",
            "Genre 'disco': 100 files found\n",
            "  Processing split 'train': 60 files\n",
            "  Processing split 'val': 20 files\n",
            "  Processing split 'test': 20 files\n",
            "\n",
            "Genre 'blues': 100 files found\n",
            "  Processing split 'train': 60 files\n",
            "  Processing split 'val': 20 files\n",
            "  Processing split 'test': 20 files\n",
            "\n",
            "Genre 'country': 100 files found\n",
            "  Processing split 'train': 60 files\n",
            "  Processing split 'val': 20 files\n",
            "  Processing split 'test': 20 files\n",
            "\n",
            "Genre 'hiphop': 100 files found\n",
            "  Processing split 'train': 60 files\n",
            "  Processing split 'val': 20 files\n",
            "  Processing split 'test': 20 files\n",
            "\n",
            "Genre 'metal': 100 files found\n",
            "  Processing split 'train': 60 files\n",
            "  Processing split 'val': 20 files\n",
            "  Processing split 'test': 20 files\n",
            "\n",
            "Genre 'reggae': 100 files found\n",
            "  Processing split 'train': 60 files\n",
            "  Processing split 'val': 20 files\n",
            "  Processing split 'test': 20 files\n",
            "\n",
            "Genre 'jazz': 100 files found\n",
            "  Processing split 'train': 60 files\n",
            "  Processing split 'val': 20 files\n",
            "  Processing split 'test': 20 files\n",
            "\n",
            "Genre 'classical': 100 files found\n",
            "  Processing split 'train': 60 files\n",
            "  Processing split 'val': 20 files\n",
            "  Processing split 'test': 20 files\n",
            "\n",
            "Done! Total spectrograms saved: 21398\n"
          ]
        }
      ],
      "source": [
        "def process_audio_files():\n",
        "    \"\"\"\n",
        "    Processes audio files, creates segments, generates spectrograms,\n",
        "    and applies time stretching augmentation to the training set\n",
        "    after saving the original spectrograms.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        segment_length = int(SEGMENT_DURATION * SAMPLE_RATE)\n",
        "        total_images = 0\n",
        "\n",
        "        genres = [d for d in os.listdir(AUDIO_INPUT_FOLDER)\n",
        "                  if os.path.isdir(os.path.join(AUDIO_INPUT_FOLDER, d))]\n",
        "\n",
        "        for genre in genres:\n",
        "            genre_path = os.path.join(AUDIO_INPUT_FOLDER, genre)\n",
        "            audio_files = glob(os.path.join(genre_path, '*.wav'))\n",
        "\n",
        "            if not audio_files:\n",
        "                print(f\"\\nGenre '{genre}': No .wav files found. Skipping.\")\n",
        "                continue\n",
        "\n",
        "            print(f\"\\nGenre '{genre}': {len(audio_files)} files found\")\n",
        "\n",
        "            random.shuffle(audio_files)\n",
        "            train_split_idx = int(0.6 * len(audio_files))\n",
        "            val_split_idx = int(0.8 * len(audio_files))\n",
        "\n",
        "            sets_files = {\n",
        "                'train': audio_files[:train_split_idx],\n",
        "                'val': audio_files[train_split_idx:val_split_idx],\n",
        "                'test': audio_files[val_split_idx:]\n",
        "            }\n",
        "\n",
        "            for split, files_in_split in sets_files.items():\n",
        "                print(f\"  Processing split '{split}': {len(files_in_split)} files\")\n",
        "\n",
        "                for path in files_in_split:\n",
        "                    try:\n",
        "                        original_audio, sr = librosa.load(path, sr=SAMPLE_RATE)\n",
        "                        file_stem = os.path.splitext(os.path.basename(path))[0]\n",
        "                        output_dir_genre_split = os.path.join(SPECTROGRAM_OUTPUT_FOLDER, split, genre)\n",
        "                        os.makedirs(output_dir_genre_split, exist_ok=True)\n",
        "\n",
        "                        versions_to_process = []\n",
        "\n",
        "                        # Add original audio for processing\n",
        "                        versions_to_process.append({\n",
        "                            \"data\": original_audio,\n",
        "                            \"label\": \"original\", \n",
        "                            \"stem\": file_stem \n",
        "                        })\n",
        "\n",
        "                        # If it's training data, prepare augmented versions\n",
        "                        # These will be processed *after* the original \n",
        "                        if split == 'train':\n",
        "                            for rate in TIME_STRETCH_RATES:\n",
        "                                try:\n",
        "                                    stretched_audio = librosa.effects.time_stretch(y=original_audio, rate=rate)\n",
        "                                    aug_label_suffix = f'ts_{str(rate).replace(\".\", \"p\")}'\n",
        "                                    versions_to_process.append({\n",
        "                                        \"data\": stretched_audio,\n",
        "                                        \"label\": aug_label_suffix,\n",
        "                                        \"stem\": f\"{file_stem}_{aug_label_suffix}\" \n",
        "                                    })\n",
        "                                except Exception as e_stretch:\n",
        "                                    print(f\"      Error stretching {file_stem} with rate {rate}: {e_stretch}\")\n",
        "\n",
        "\n",
        "                        # Process each version (original, then augmented if applicable)\n",
        "                        for audio_version_info in versions_to_process:\n",
        "                            current_audio_data = audio_version_info[\"data\"]\n",
        "                            current_file_stem_for_segments = audio_version_info[\"stem\"]\n",
        "                            \n",
        "                            # Calculate number of possible segments for this specific audio data\n",
        "                            num_possible_segments = len(current_audio_data) // segment_length\n",
        "\n",
        "                            if num_possible_segments == 0:\n",
        "                                print(f\"Skipping {current_file_stem_for_segments} due to insufficient length for segmentation.\")\n",
        "                                continue\n",
        "\n",
        "                            else:\n",
        "                                segments_data = []\n",
        "                                for i in range(num_possible_segments):\n",
        "                                    start = i * segment_length\n",
        "                                    end = start + segment_length\n",
        "                                    segment = current_audio_data[start:end]\n",
        "                                    segments_data.append((segment, i))\n",
        "\n",
        "                            # Process and save segments for the current audio version\n",
        "                            for segment_audio, seg_idx in segments_data:\n",
        "\n",
        "                                spec = generate_mel_spectrogram(segment_audio, sr)\n",
        "\n",
        "                                img_filename = f\"{current_file_stem_for_segments}_seg_{seg_idx+1}.png\"\n",
        "                                img_path = os.path.join(output_dir_genre_split, img_filename)\n",
        "                                \n",
        "                                plt.imsave(img_path, np.ascontiguousarray(np.flipud(spec)), cmap='viridis', origin='lower')\n",
        "                                total_images += 1\n",
        "\n",
        "                    except Exception as e_file:\n",
        "                        print(f\"Error processing file {path}: {e_file}\")\n",
        "        print(f\"\\nDone! Total spectrograms saved: {total_images}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error in process_audio_files: {e}\")\n",
        "\n",
        "process_audio_files()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
